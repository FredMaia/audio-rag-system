# ğŸ“ Projeto de IntegraÃ§Ã£o RAG + Whisper

## ğŸ§  Arquitetura DistribuÃ­da para TranscriÃ§Ã£o e Resposta Inteligente

### ğŸ“˜ VisÃ£o Geral
Este projeto foi desenvolvido como parte das atividades acadÃªmicas do curso de **CiÃªncia da ComputaÃ§Ã£o** na **Universidade Federal de Lavras (UFLA)**.  
Seu objetivo Ã© integrar **modelos de transcriÃ§Ã£o de Ã¡udio (Whisper)** e **geraÃ§Ã£o de respostas inteligentes (RAG com Groq API)** por meio de uma **arquitetura distribuÃ­da baseada em microsserviÃ§os**.

A soluÃ§Ã£o permite o envio de um Ã¡udio, sua transcriÃ§Ã£o automÃ¡tica e o processamento semÃ¢ntico do texto resultante, retornando uma resposta inteligente ao usuÃ¡rio.

---

## ğŸ‘¥ Integrantes
- **Rafael Rezende**  
- **Frederico Maia**  
- **Mateus Mendes**  

---

## âš™ï¸ Arquitetura do Sistema

O sistema Ã© composto por trÃªs microsserviÃ§os principais, orquestrados via **Docker Compose**:

```
+-----------------+       +------------------+       +----------------------+
|                 |       |                  |       |                      |
|  API Gateway    +------>+ Whisper Service  +------>+   RAG Service (Groq) |
|  (FastAPI)      |       |  (TranscriÃ§Ã£o)   |       |  (GeraÃ§Ã£o de Resposta)|
|                 |       |                  |       |                      |
+-----------------+       +------------------+       +----------------------+
         |                                                         
         +--> Retorna TranscriÃ§Ã£o + Resposta Final
```

---

## ğŸ”¹ DescriÃ§Ã£o dos Componentes

### **1. Whisper Service (`whisper_service.py`)**
- ResponsÃ¡vel pela **transcriÃ§Ã£o automÃ¡tica de Ã¡udios** utilizando o modelo **OpenAI Whisper (base)**.  
- Suporta mÃºltiplos formatos: `.mp3`, `.wav`, `.m4a`, `.ogg`, `.flac`, `.webm`, `.mp4`.  
- Implementado com **FastAPI** e **Uvicorn**.  
- Containerizado e exposto na **porta 8001**.

---

### **2. RAG Service (`rag_service.py`)**
- Executa a **geraÃ§Ã£o de respostas contextuais** utilizando o modelo **LLaMA-3.3-70B (Groq API)**.  
- Recebe a transcriÃ§Ã£o e processa com um **contexto base embutido**.  
- Implementado com **FastAPI** e **Groq SDK**.  
- Exposto na **porta 8002**.

---

### **3. Gateway (`gateway.py`)**
- Ponto central de comunicaÃ§Ã£o do sistema.  
- ResponsÃ¡vel por:  
  1. Receber o Ã¡udio do usuÃ¡rio.  
  2. Encaminhar para o Whisper Service â†’ obter transcriÃ§Ã£o.  
  3. Enviar transcriÃ§Ã£o ao RAG Service â†’ obter resposta.  
  4. Retornar ambos ao cliente.  
- Exposto na **porta 8000**.

---

## ğŸ§± Estrutura do Projeto

```
ğŸ“‚ projeto-rag-whisper/
â”œâ”€â”€ ğŸ“„ Dockerfile
â”œâ”€â”€ ğŸ“„ docker-compose.yml
â”œâ”€â”€ ğŸ“„ gateway.py
â”œâ”€â”€ ğŸ“„ whisper_service.py
â”œâ”€â”€ ğŸ“„ rag_service.py
â”œâ”€â”€ ğŸ“„ requirements-gateway.txt
â”œâ”€â”€ ğŸ“„ requirements-whisper.txt
â”œâ”€â”€ ğŸ“„ requirements-rag.txt
â””â”€â”€ ğŸ“ docs/
    â””â”€â”€ ğŸ“„ README.md (este documento)
```

---

## ğŸ³ ExecuÃ§Ã£o com Docker

### ğŸ”§ PrÃ©-requisitos
- **Docker** e **Docker Compose** instalados.  
- Chave de API vÃ¡lida da **Groq**, configurada como variÃ¡vel de ambiente:

```bash
export GROQ_API_KEY="sua_chave_aqui"
```

### â–¶ï¸ Passos para ExecuÃ§Ã£o

```bash
# Clone o repositÃ³rio
git clone https://github.com/FredMaia/audio-rag-system.git
cd projeto-rag-whisper

# Inicie os serviÃ§os
docker-compose up --build
```

### ğŸŒ Endpoints DisponÃ­veis
- **Gateway:** http://localhost:8000  
- **Whisper Service:** http://localhost:8001  
- **RAG Service:** http://localhost:8002  

---

## ğŸ§© Fluxo de OperaÃ§Ã£o

1. O usuÃ¡rio envia um arquivo de Ã¡udio (`.mp3`, `.wav`, etc.) para o endpoint `/process-audio` do **Gateway**.  
2. O **Gateway** encaminha o Ã¡udio ao **Whisper Service** para transcriÃ§Ã£o.  
3. O texto transcrito Ã© enviado ao **RAG Service**, que gera uma resposta contextual utilizando a **Groq API**.  
4. O **Gateway** retorna o resultado final:

```json
{
  "transcription": "texto reconhecido",
  "answer": "resposta gerada",
  "model": "llama-3.3-70b-versatile"
}
```

---

## ğŸ§  Tecnologias Utilizadas

| Tecnologia | FunÃ§Ã£o Principal |
|-------------|------------------|
| **Python 3.10** | Linguagem base |
| **FastAPI** | Framework web dos serviÃ§os |
| **OpenAI Whisper** | TranscriÃ§Ã£o de Ã¡udio |
| **Groq API (LLaMA 3.3)** | GeraÃ§Ã£o de respostas |
| **Uvicorn** | Servidor ASGI |
| **Docker Compose** | OrquestraÃ§Ã£o de microsserviÃ§os |
| **HTTPX** | RequisiÃ§Ãµes assÃ­ncronas entre serviÃ§os |

---

## ğŸ” ConsideraÃ§Ãµes Finais
O projeto demonstra uma integraÃ§Ã£o prÃ¡tica entre **IA generativa** e **processamento de Ã¡udio**, com foco em **modularidade**, **escalabilidade** e **clareza arquitetural**.  
A abordagem baseada em microsserviÃ§os garante independÃªncia entre componentes, facilitando futuras expansÃµes â€” como **vetorizaÃ§Ã£o**, **cache semÃ¢ntico** ou **autenticaÃ§Ã£o**.
